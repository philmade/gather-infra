#!/bin/sh
# claw-browse — agent browser harness for Chawan
# Provides a clean programmatic interface over cha(1) for PicoClaw agents.
#
# Usage:
#   claw-browse fetch <url>                  Dump page content with metadata
#   claw-browse links <url>                  Extract links only
#   claw-browse screenshot <url>             Raw text dump (terminal screenshot)
#   claw-browse interact <url> [options]     Navigate interactively
#     --follow N                             Follow link number N
#     --script 'js...'                       Run pager script
#   claw-browse search <query>               Search via DuckDuckGo HTML
#
# Environment:
#   CLAW_BROWSE_TIMEOUT   Page load timeout in seconds (default: 15)
#   CLAW_BROWSE_UA        Custom user-agent string
#   CLAW_BROWSE_JS        Enable JavaScript: 0|1|app (default: 0)
#   CLAW_BROWSE_COOKIES   Enable cookies: 0|1|save (default: 1)

set -eu

TIMEOUT="${CLAW_BROWSE_TIMEOUT:-15}"
JS="${CLAW_BROWSE_JS:-0}"
COOKIES="${CLAW_BROWSE_COOKIES:-1}"
CONFIG_DIR="${CLAW_BROWSE_CONFIG:-/etc/claw-browse}"
CHA="${CHA_BIN:-cha}"

die() { echo "error: $*" >&2; exit 1; }

# Build cha flags based on environment
cha_flags() {
    flags="-d"
    if [ -f "$CONFIG_DIR/config.toml" ]; then
        flags="$flags -C $CONFIG_DIR/config.toml"
    fi
    case "$JS" in
        1|true)  flags="$flags -o buffer.scripting=true" ;;
        app)     flags="$flags -o buffer.scripting=\"app\"" ;;
    esac
    case "$COOKIES" in
        1|true)  flags="$flags -o buffer.cookie=true" ;;
        save)    flags="$flags -o buffer.cookie=\"save\"" ;;
        0|false) ;;
    esac
    echo "$flags"
}

# Run cha with timeout
run_cha() {
    url="$1"
    shift
    eval timeout "$TIMEOUT" "$CHA" $(cha_flags) "$@" "'$url'" 2>/dev/null
}

# Sanitize URL — add https:// if missing
normalize_url() {
    case "$1" in
        http://*|https://*) echo "$1" ;;
        *) echo "https://$1" ;;
    esac
}

# === COMMANDS ===

cmd_fetch() {
    [ $# -lt 1 ] && die "usage: claw-browse fetch <url>"
    url=$(normalize_url "$1")

    raw=$(run_cha "$url") || die "failed to load $url"

    # Separate content from link references (URLs at bottom: [N] https://...)
    content=$(echo "$raw" | sed '/^\[1\] [a-z]*:/,$d')
    links=$(echo "$raw" | sed -n '/^\[1\] [a-z]*:/,$p')

    # Extract title from first non-empty content line
    title=$(echo "$content" | head -5 | sed 's/^[[:space:]]*//' | sed 's/\[[0-9]*\]//g' | grep -v '^$' | head -1)

    echo "=== PAGE ==="
    echo "url: $url"
    echo "title: $title"
    echo ""
    echo "=== CONTENT ==="
    echo "$content" | sed 's/^[[:space:]]*$//' | sed '/^$/N;/^\n$/d'
    if [ -n "$links" ]; then
        echo ""
        echo "=== LINKS ==="
        echo "$links"
    fi
    echo "=== END ==="
}

cmd_links() {
    [ $# -lt 1 ] && die "usage: claw-browse links <url>"
    url=$(normalize_url "$1")

    raw=$(run_cha "$url") || die "failed to load $url"

    # Extract link references from bottom of dump (URLs: [N] https://...)
    echo "$raw" | sed -n '/^\[1\] [a-z]*:/,$p'
}

cmd_screenshot() {
    [ $# -lt 1 ] && die "usage: claw-browse screenshot <url>"
    url=$(normalize_url "$1")

    run_cha "$url" || die "failed to load $url"
}

cmd_interact() {
    [ $# -lt 1 ] && die "usage: claw-browse interact <url> [--follow N] [--script '...']"
    url=$(normalize_url "$1")
    shift

    follow=""
    script=""
    while [ $# -gt 0 ]; do
        case "$1" in
            --follow)
                [ $# -lt 2 ] && die "--follow requires a link number"
                follow="$2"; shift 2 ;;
            --script)
                [ $# -lt 2 ] && die "--script requires a script string"
                script="$2"; shift 2 ;;
            *) die "unknown option: $1" ;;
        esac
    done

    if [ -n "$follow" ]; then
        # Fetch page, extract target URL for link N, then fetch that
        raw=$(run_cha "$url") || die "failed to load $url"
        target=$(echo "$raw" | sed -n "s/^\[$follow\] \([a-z]*:.*\)/\1/p")
        [ -z "$target" ] && die "link [$follow] not found on page"
        echo "following link [$follow] → $target"
        echo ""
        cmd_fetch "$target"
    elif [ -n "$script" ]; then
        # Run a pager-level script against the page
        eval timeout "$TIMEOUT" "$CHA" \
            -o 'start.headless=true' \
            $(cha_flags | sed 's/-d//') \
            -r "'$script'" \
            "'$url'" 2>/dev/null
    else
        die "interact requires --follow or --script"
    fi
}

cmd_search() {
    [ $# -lt 1 ] && die "usage: claw-browse search <query>"
    query=$(echo "$*" | sed 's/ /+/g')
    url="https://html.duckduckgo.com/html/?q=$query"
    cmd_fetch "$url"
}

cmd_help() {
    sed -n '2,/^$/{ s/^# //; s/^#//; p }' "$0"
}

# === MAIN ===

[ $# -lt 1 ] && { cmd_help; exit 1; }

command="$1"
shift

case "$command" in
    fetch)      cmd_fetch "$@" ;;
    links)      cmd_links "$@" ;;
    screenshot) cmd_screenshot "$@" ;;
    interact)   cmd_interact "$@" ;;
    search)     cmd_search "$@" ;;
    help|--help|-h) cmd_help ;;
    *) die "unknown command: $command (try: fetch, links, screenshot, interact, search)" ;;
esac
